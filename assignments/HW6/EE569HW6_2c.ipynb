{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"EE569HW6_2c.ipynb","provenance":[],"authorship_tag":"ABX9TyMAjG6zv2lz5+w6p/bPa8Bs"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"kW4lkzMo78XN","colab":{"base_uri":"https://localhost:8080/","height":285},"executionInfo":{"status":"error","timestamp":1651452619570,"user_tz":420,"elapsed":5660,"user":{"displayName":"Hanyun Zhao","userId":"16373381763566944252"}},"outputId":"59d2a780-d700-4a4e-8673-a01031e07e56"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n","here\n"]},{"output_type":"error","ename":"TypeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-970e68bd2d3b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    133\u001b[0m p2 = Pixelhop(depth=3, TH1=0.005, TH2=0.001,\n\u001b[1;32m    134\u001b[0m             SaabArgs=SaabArgs, shrinkArgs=shrinkArgs, concatArg=concatArg)\n\u001b[0;32m--> 135\u001b[0;31m \u001b[0mp2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mBS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[0;31m# --------- Module 2: get only Hop 3 feature for both training set and testing set -----------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: fit() got an unexpected keyword argument 'batch_size'"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive/')\n","import sys\n","sys.path.append('/content/drive/MyDrive/HW6')\n","\n","import numpy as np\n","from tensorflow.keras.datasets import mnist,fashion_mnist\n","from skimage.util import view_as_windows\n","from pixelhop import Pixelhop\n","from skimage.measure import block_reduce\n","import xgboost as xgb\n","import warnings, gc\n","import time\n","from sklearn.metrics import confusion_matrix, accuracy_score\n","\n","\n","\n","np.random.seed(1)\n","\n","# Preprocess\n","N_Train_Reduced = 10000    # 10000\n","N_Train_Full = 60000     # 50000\n","N_Test = 10000            # 10000\n","\n","BS = 2000 # batch size\n","\n","\n","def shuffle_data(X, y):\n","    shuffle_idx = np.random.permutation(y.size)\n","    X = X[shuffle_idx]\n","    y = y[shuffle_idx]\n","    return X, y\n","\n","\n","def select_balanced_subset(images, labels, use_num_images):\n","    '''\n","    select equal number of images from each classes\n","    '''\n","    num_total, H, W, C = images.shape\n","    num_class = np.unique(labels).size\n","    num_per_class = int(use_num_images / num_class)\n","\n","    # Shuffle\n","    images, labels = shuffle_data(images, labels)\n","\n","    selected_images = np.zeros((use_num_images, H, W, C))\n","    selected_labels = np.zeros(use_num_images)\n","\n","    for i in range(num_class):\n","        selected_images[i * num_per_class:(i + 1) * num_per_class] = images[labels == i][:num_per_class]\n","        selected_labels[i * num_per_class:(i + 1) * num_per_class] = np.ones((num_per_class)) * i\n","\n","    # Shuffle again\n","    selected_images, selected_labels = shuffle_data(selected_images, selected_labels)\n","\n","    return selected_images, selected_labels\n","\n","def Shrink(X, shrinkArg):\n","    #---- max pooling---- (2x2) -to- (1x1)\n","    pool = shrinkArg['pool']\n","    # TODO: fill in the rest of max pooling\n","    if pool:\n","        N, H, W, C = X.shape\n","        if H%2!=0 or W%2!=0:\n","          print(\"non even height or width\")\n","        pool_out=np.zeros((N,int(H/2),int(W/2),C),dtype=int)\n","        for n in range(N):\n","            for c in range(C):\n","                for h in range(int(H/2)):\n","                    for w in range(int(W/2)):\n","                        pool_out[n,h,w,c]=X[n,h*2:h*2+1,w*2:w*2+1,c].max()\n","    else:\n","        pool_out=X\n","\n","    #---- neighborhood construction\n","    win = shrinkArg['win']\n","    stride = shrinkArg['stride']\n","    pad = shrinkArg['pad']\n","    ch=pool_out.shape[-1]\n","    # TODO: fill in the rest of neighborhood construction\n","\n","    if pad>0:\n","        out=np.pad(pool_out,((0,0), (pad,pad), (pad,pad), (0,0)), 'reflect')\n","    else:\n","        out=pool_out\n","    out = view_as_windows(out, (1, win, win, ch), (1, stride, stride, ch))\n","    return out.reshape(out.shape[0], out.shape[1], out.shape[2], -1)\n","\n","\n","# example callback function for how to concate features from different hops\n","def Concat(X, concatArg):\n","    return X\n","\n","def get_feat(X, num_layers=3):\n","    output = p2.transform_singleHop(X,layer=0)\n","    if num_layers>1:\n","        for i in range(num_layers-1):\n","            output = p2.transform_singleHop(output, layer=i+1)\n","    return output\n","\n","\n","\n","warnings.filterwarnings(\"ignore\")\n","# ---------- Load MNIST data and split ----------\n","(x_train, y_train), _ = mnist.load_data()\n","\n","\n","# -----------Data Preprocessing-----------\n","x_train = np.asarray(x_train,dtype='float32')[:,:,:,np.newaxis]\n","#x_test = np.asarray(x_test,dtype='float32')[:,:,:,np.newaxis]\n","y_train = np.asarray(y_train,dtype='int')\n","#y_test = np.asarray(y_test,dtype='int')\n","\n","# if use only 10000 images train pixelhop\n","#x_train_reduced, y_train_reduced = select_balanced_subset(x_train, y_train, use_num_images=N_Train_Reduced)\n","\n","x_train /= 255.0\n","#x_test /= 255.0\n","#x_train_reduced /=255.0\n","\n","# -----------Module 1: set PixelHop parameters-----------\n","# TODO: fill in this part\n","SaabArgs = [{'num_AC_kernels':-1, 'needBias':False, 'cw': False},\n","            {'num_AC_kernels':-1, 'needBias':True, 'cw':True},\n","            {'num_AC_kernels':-1, 'needBias':True, 'cw':True}]\n","shrinkArgs = [{'func':Shrink, 'win':5, 'stride': 1,'pad':2,'pool':False},\n","            {'func': Shrink, 'win':5, 'stride': 1,'pad':0,'pool':True},\n","            {'func': Shrink, 'win':5, 'stride': 1,'pad':0,'pool':True}]\n","concatArg = {'func':Concat}\n","print(\"here\")\n","# -----------Module 1: Train PixelHop -----------\n","# TODO: fill in this part\n","p2 = Pixelhop(depth=3, TH1=0.005, TH2=0.001,\n","            SaabArgs=SaabArgs, shrinkArgs=shrinkArgs, concatArg=concatArg)\n","p2.fit(x_train)\n","\n","# --------- Module 2: get only Hop 3 feature for both training set and testing set -----------\n","# you can get feature \"batch wise\" and concatenate them if your memory is restricted\n","# TODO: fill in this part\n","x_train_feature=[]\n","x_test_feature=[]\n","for i in range(int(x_train.shape[0]/BS)):\n","  train_hop3_feats = get_feat(x_train[2000*i:2000*i+2000]) #get_feat is already set to get 3rd feat\n","  x_train_feature.append(train_hop3_feats)\n","  # test_hop3_feats = get_feat(x_test[2000*i:2000*i+2000])\n","  # x_test_feature.append(test_hop3_feats)\n","\n","train_hop3_feats=x_train_feature[0]\n","for i in range(1,int(x_train.shape[0]/BS)):\n","  train_hop3_feats=np.concatenate((train_hop3_feats,x_train_feature[i]),axis=0)\n","# test_hop3_feats=np.concatenate((x_test_feature[0],x_test_feature[1],x_test_feature[2],x_test_feature[3],x_test_feature[4]),axis=0)\n","print(\"train hop3 feature\",train_hop3_feats.shape)\n","#test_hop3_feats = get_feat(x_test)\n","\n","\n","# --------- Module 2: standardization\n","STD = np.std(train_hop3_feats, axis=0, keepdims=1)\n","train_hop3_feats = train_hop3_feats/STD\n","#test_hop3_feats = test_hop3_feats/STD\n","\n","train_hop3_feats = np.reshape(train_hop3_feats,(60000,train_hop3_feats.shape[3]))\n","#test_hop3_feats = np.reshape(test_hop3_feats,(10000,test_hop3_feats.shape[3]))\n","\n","#---------- Module 3: Train XGBoost classifier on hop3 feature ---------\n","\n","tr_acc = []\n","te_acc = []\n","\n","clf = xgb.XGBClassifier(n_jobs=-1,\n","                    objective='multi:softprob',\n","                    # tree_method='gpu_hist', gpu_id=None,\n","                    max_depth=6,n_estimators=100,\n","                    min_child_weight=5,gamma=5,\n","                    subsample=0.8,learning_rate=0.1,\n","                    nthread=8,colsample_bytree=1.0)\n","\n","# train_hop3_feats = np.reshape(train_hop3_feats,(10000,train_hop3_feats.shape[3]))\n","\n","# test_hop3_feats = np.reshape(test_hop3_feats,(10000,test_hop3_feats.shape[3]))\n","clf.fit(train_hop3_feats, y_train)\n","\n","train_pred = clf.predict(train_hop3_feats)\n","# test_pred = clf.predict(test_hop3_feats)\n","\n","train_acc = accuracy_score(y_train, train_pred)\n","#test_acc = accuracy_score(y_test, test_pred)\n","print(\"train accuracy\",train_acc)\n","# print(\"test accuracy\",test_acc)\n","\n","\n","K1=len(p2.Energy[\"Layer0\"])\n","K2=sum([len(i) for i in p2.Energy[\"Layer1\"]])\n","K3=sum([len(i) for i in p2.Energy[\"Layer2\"]])\n","print(\"K1\",K1,\"K2\",K2,\"K3\",K3)\n","print(\"total number of parameter\", 25*(K1+K2+K3))\n","\n","\n","############################\n","#failed due to RAM size"]},{"cell_type":"code","source":[""],"metadata":{"id":"UkjyZ9UeRSJp"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":2,"metadata":{"id":"25nCL8n3KQEw","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1651454121677,"user_tz":420,"elapsed":1085799,"user":{"displayName":"Hanyun Zhao","userId":"16373381763566944252"}},"outputId":"16ff7498-fba5-4bfb-ada4-19426a1a98d1"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n","=============================================>c/w Saab Train Hop 1\n","=============================================>c/w Saab Train Hop 2\n","=============================================>c/w Saab Train Hop 3\n","train accuracy 0.9701\n","test accuracy 0.9168\n","K1 1 K2 134 K3 111\n","total number of parameter 375225\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive/')\n","import sys\n","sys.path.append('/content/drive/MyDrive/HW6')\n","\n","import numpy as np\n","from tensorflow.keras.datasets import mnist,fashion_mnist\n","from skimage.util import view_as_windows\n","from pixelhop import Pixelhop\n","from skimage.measure import block_reduce\n","import xgboost as xgb\n","import warnings, gc\n","import time\n","from sklearn.metrics import confusion_matrix, accuracy_score\n","\n","\n","\n","np.random.seed(1)\n","\n","# Preprocess\n","N_Train_Reduced = 10000    # 10000\n","N_Train_Full = 60000     # 50000\n","N_Test = 10000            # 10000\n","\n","BS = 2000 # batch size\n","\n","\n","def shuffle_data(X, y):\n","    shuffle_idx = np.random.permutation(y.size)\n","    X = X[shuffle_idx]\n","    y = y[shuffle_idx]\n","    return X, y\n","\n","\n","def select_balanced_subset(images, labels, use_num_images):\n","    '''\n","    select equal number of images from each classes\n","    '''\n","    num_total, H, W, C = images.shape\n","    num_class = np.unique(labels).size\n","    num_per_class = int(use_num_images / num_class)\n","\n","    # Shuffle\n","    images, labels = shuffle_data(images, labels)\n","\n","    selected_images = np.zeros((use_num_images, H, W, C))\n","    selected_labels = np.zeros(use_num_images)\n","\n","    for i in range(num_class):\n","        selected_images[i * num_per_class:(i + 1) * num_per_class] = images[labels == i][:num_per_class]\n","        selected_labels[i * num_per_class:(i + 1) * num_per_class] = np.ones((num_per_class)) * i\n","\n","    # Shuffle again\n","    selected_images, selected_labels = shuffle_data(selected_images, selected_labels)\n","\n","    return selected_images, selected_labels\n","\n","def Shrink(X, shrinkArg):\n","    #---- max pooling---- (2x2) -to- (1x1)\n","    pool = shrinkArg['pool']\n","    # TODO: fill in the rest of max pooling\n","    if pool:\n","        N, H, W, C = X.shape\n","        if H%2!=0 or W%2!=0:\n","          print(\"non even height or width\")\n","        pool_out=np.zeros((N,int(H/2),int(W/2),C),dtype=int)\n","        for n in range(N):\n","            for c in range(C):\n","                for h in range(int(H/2)):\n","                    for w in range(int(W/2)):\n","                        pool_out[n,h,w,c]=X[n,h*2:h*2+1,w*2:w*2+1,c].max()\n","    else:\n","        pool_out=X\n","\n","    #---- neighborhood construction\n","    win = shrinkArg['win']\n","    stride = shrinkArg['stride']\n","    pad = shrinkArg['pad']\n","    ch=pool_out.shape[-1]\n","    # TODO: fill in the rest of neighborhood construction\n","\n","    if pad>0:\n","        out=np.pad(pool_out,((0,0), (pad,pad), (pad,pad), (0,0)), 'reflect')\n","    else:\n","        out=pool_out\n","    out = view_as_windows(out, (1, win, win, ch), (1, stride, stride, ch))\n","    return out.reshape(out.shape[0], out.shape[1], out.shape[2], -1)\n","\n","\n","# example callback function for how to concate features from different hops\n","def Concat(X, concatArg):\n","    return X\n","\n","def get_feat(X, num_layers=3):\n","    output = p2.transform_singleHop(X,layer=0)\n","    if num_layers>1:\n","        for i in range(num_layers-1):\n","            output = p2.transform_singleHop(output, layer=i+1)\n","    return output\n","\n","\n","\n","warnings.filterwarnings(\"ignore\")\n","# ---------- Load MNIST data and split ----------\n","(x_train, y_train), (x_test,y_test) = mnist.load_data()\n","\n","\n","# -----------Data Preprocessing-----------\n","x_train = np.asarray(x_train,dtype='float32')[:,:,:,np.newaxis]\n","x_test = np.asarray(x_test,dtype='float32')[:,:,:,np.newaxis]\n","y_train = np.asarray(y_train,dtype='int')\n","y_test = np.asarray(y_test,dtype='int')\n","\n","# if use only 10000 images train pixelhop\n","x_train_reduced, y_train_reduced = select_balanced_subset(x_train, y_train, use_num_images=N_Train_Reduced)\n","\n","x_train /= 255.0\n","x_test /= 255.0\n","x_train_reduced /=255.0\n","\n","#TODO:\n","\n","# train_accuracy=[]\n","# test_accuracy=[]\n","# modelSize=[]\n","\n","# -----------Module 1: set PixelHop parameters-----------\n","# TODO: fill in this part\n","SaabArgs = [{'num_AC_kernels':-1, 'needBias':False, 'cw': False},\n","            {'num_AC_kernels':-1, 'needBias':True, 'cw':True},\n","            {'num_AC_kernels':-1, 'needBias':True, 'cw':True}]\n","shrinkArgs = [{'func':Shrink, 'win':5, 'stride': 1,'pad':2,'pool':False},\n","            {'func': Shrink, 'win':5, 'stride': 1,'pad':0,'pool':True},\n","            {'func': Shrink, 'win':5, 'stride': 1,'pad':0,'pool':True}]\n","concatArg = {'func':Concat}\n","\n","# -----------Module 1: Train PixelHop -----------\n","# TODO: fill in this part\n","p2 = Pixelhop(depth=3, TH1=0.005, TH2=0.001,\n","            SaabArgs=SaabArgs, shrinkArgs=shrinkArgs, concatArg=concatArg)\n","p2.fit(x_train_reduced)\n","\n","# --------- Module 2: get only Hop 3 feature for both training set and testing set -----------\n","# you can get feature \"batch wise\" and concatenate them if your memory is restricted\n","# TODO: fill in this part\n","x_train_feature=[]\n","x_test_feature=[]\n","for i in range(5):\n","  train_hop3_feats = get_feat(x_train_reduced[2000*i:2000*i+2000]) #get_feat is already set to get 3rd feat\n","  x_train_feature.append(train_hop3_feats)\n","  test_hop3_feats = get_feat(x_test[2000*i:2000*i+2000])\n","  x_test_feature.append(test_hop3_feats)\n","\n","train_hop3_feats=np.concatenate((x_train_feature[0],x_train_feature[1],x_train_feature[2],x_train_feature[3],x_train_feature[4]),axis=0)\n","test_hop3_feats=np.concatenate((x_test_feature[0],x_test_feature[1],x_test_feature[2],x_test_feature[3],x_test_feature[4]),axis=0)\n","\n","#test_hop3_feats = get_feat(x_test)\n","\n","\n","# --------- Module 2: standardization\n","STD = np.std(train_hop3_feats, axis=0, keepdims=1)\n","train_hop3_feats = train_hop3_feats/STD\n","test_hop3_feats = test_hop3_feats/STD\n","\n","train_hop3_feats = np.reshape(train_hop3_feats,(10000,train_hop3_feats.shape[3]))\n","test_hop3_feats = np.reshape(test_hop3_feats,(10000,test_hop3_feats.shape[3]))\n","\n","#---------- Module 3: Train XGBoost classifier on hop3 feature ---------\n","\n","tr_acc = []\n","te_acc = []\n","\n","clf = xgb.XGBClassifier(n_jobs=-1,\n","                    objective='multi:softprob',\n","                    # tree_method='gpu_hist', gpu_id=None,\n","                    max_depth=6,n_estimators=100,\n","                    min_child_weight=5,gamma=5,\n","                    subsample=0.8,learning_rate=0.1,\n","                    nthread=8,colsample_bytree=1.0)\n","\n","# train_hop3_feats = np.reshape(train_hop3_feats,(10000,train_hop3_feats.shape[3]))\n","\n","# test_hop3_feats = np.reshape(test_hop3_feats,(10000,test_hop3_feats.shape[3]))\n","clf.fit(train_hop3_feats, y_train_reduced)\n","\n","train_pred = clf.predict(train_hop3_feats)\n","test_pred = clf.predict(test_hop3_feats)\n","\n","train_acc = accuracy_score(y_train_reduced, train_pred)\n","test_acc = accuracy_score(y_test, test_pred)\n","print(\"train accuracy\",train_acc)\n","print(\"test accuracy\",test_acc)\n","\n","\n","K1=len(p2.Energy[\"Layer0\"])\n","K2=sum([len(i) for i in p2.Energy[\"Layer1\"]])\n","K3=sum([len(i) for i in p2.Energy[\"Layer2\"]])\n","print(\"K1\",K1,\"K2\",K2,\"K3\",K3)\n","print(\"total number of parameter\", 25*K1+25*K1*K2+25*K2*K3)\n"]},{"cell_type":"code","source":["cm=confusion_matrix(y_train_reduced,train_pred)\n","print(cm)\n","print(cm/10000)\n","import seaborn as sns\n","sns.heatmap(cm)\n"],"metadata":{"id":"kMLGzQXpYFkZ","executionInfo":{"status":"ok","timestamp":1651454798367,"user_tz":420,"elapsed":1318,"user":{"displayName":"Hanyun Zhao","userId":"16373381763566944252"}},"outputId":"22aca5b6-cf24-41d2-8a30-ba3adfafc6a2","colab":{"base_uri":"https://localhost:8080/","height":651}},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["[[985   0   1   0   2   5   1   0   6   0]\n"," [  0 985   6   0   1   1   1   3   3   0]\n"," [  0   2 970   2   2   2   5   8   6   3]\n"," [  1   1   9 961   0  15   0   6   4   3]\n"," [  0   1   1   0 966   0   8   1   1  22]\n"," [  1   3   3  10   4 975   1   0   2   1]\n"," [  4   0   0   0   3   3 987   0   3   0]\n"," [  0   1   4   0   4   2   0 972   4  13]\n"," [  2   6   5   6   2  12   4   4 955   4]\n"," [  7   2   1   4  18   5   3   9   6 945]]\n","[[0.0985 0.     0.0001 0.     0.0002 0.0005 0.0001 0.     0.0006 0.    ]\n"," [0.     0.0985 0.0006 0.     0.0001 0.0001 0.0001 0.0003 0.0003 0.    ]\n"," [0.     0.0002 0.097  0.0002 0.0002 0.0002 0.0005 0.0008 0.0006 0.0003]\n"," [0.0001 0.0001 0.0009 0.0961 0.     0.0015 0.     0.0006 0.0004 0.0003]\n"," [0.     0.0001 0.0001 0.     0.0966 0.     0.0008 0.0001 0.0001 0.0022]\n"," [0.0001 0.0003 0.0003 0.001  0.0004 0.0975 0.0001 0.     0.0002 0.0001]\n"," [0.0004 0.     0.     0.     0.0003 0.0003 0.0987 0.     0.0003 0.    ]\n"," [0.     0.0001 0.0004 0.     0.0004 0.0002 0.     0.0972 0.0004 0.0013]\n"," [0.0002 0.0006 0.0005 0.0006 0.0002 0.0012 0.0004 0.0004 0.0955 0.0004]\n"," [0.0007 0.0002 0.0001 0.0004 0.0018 0.0005 0.0003 0.0009 0.0006 0.0945]]\n"]},{"output_type":"execute_result","data":{"text/plain":["<matplotlib.axes._subplots.AxesSubplot at 0x7f9340c6de50>"]},"metadata":{},"execution_count":3},{"output_type":"display_data","data":{"text/plain":["<Figure size 432x288 with 2 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}}]}]}